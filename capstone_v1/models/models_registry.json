{
  "meta-llama/Llama-2-7b-chat-hf": {
    "model_id": "meta-llama/Llama-2-7b-chat-hf",
    "name": "Llama 2 7B Chat",
    "provider": "huggingface",
    "type": "chat",
    "access_method": "both",
    "description": "Meta's Llama 2 7B chat model optimized for dialogue use cases",
    "api_endpoint": {
      "url": "https://api-inference.huggingface.co/models/meta-llama/Llama-2-7b-chat-hf",
      "method": "POST",
      "auth_required": true,
      "rate_limit": "30 requests/minute (free tier)"
    },
    "local_endpoint": "meta-llama/Llama-2-7b-chat-hf",
    "specs": {
      "parameters": 7,
      "context_window": 4096,
      "architecture": "Transformer"
    },
    "license": "Llama 2 Community License",
    "license_url": "https://ai.meta.com/llama/license/",
    "api_key_required": true,
    "api_key_env_var": "HUGGINGFACE_API_KEY",
    "api_key_url": "https://huggingface.co/settings/tokens",
    "cost_per_1k_tokens": null,
    "free_tier_available": true,
    "free_tier_limits": "30 requests/minute",
    "recommended_use_cases": [
      "Conversational AI",
      "Customer support",
      "General Q&A",
      "Content generation"
    ],
    "limitations": [
      "Requires HuggingFace account approval for gated models",
      "Context window limited to 4K tokens",
      "May require GPU for local inference"
    ],
    "documentation_url": "https://huggingface.co/meta-llama/Llama-2-7b-chat-hf",
    "model_card_url": "https://huggingface.co/meta-llama/Llama-2-7b-chat-hf",
    "supported_languages": [
      "en",
      "es",
      "fr",
      "de",
      "it",
      "pt",
      "pl",
      "ru",
      "ja",
      "ko",
      "zh"
    ],
    "max_output_tokens": 4096,
    "default_temperature": 0.7,
    "default_max_tokens": 512
  },
  "meta-llama/Llama-2-13b-chat-hf": {
    "model_id": "meta-llama/Llama-2-13b-chat-hf",
    "name": "Llama 2 13B Chat",
    "provider": "huggingface",
    "type": "chat",
    "access_method": "both",
    "description": "Meta's Llama 2 13B chat model with improved capabilities",
    "api_endpoint": {
      "url": "https://api-inference.huggingface.co/models/meta-llama/Llama-2-13b-chat-hf",
      "method": "POST",
      "auth_required": true,
      "rate_limit": "20 requests/minute (free tier)"
    },
    "local_endpoint": "meta-llama/Llama-2-13b-chat-hf",
    "specs": {
      "parameters": 13,
      "context_window": 4096,
      "architecture": "Transformer"
    },
    "license": "Llama 2 Community License",
    "license_url": "https://ai.meta.com/llama/license/",
    "api_key_required": true,
    "api_key_env_var": "HUGGINGFACE_API_KEY",
    "api_key_url": "https://huggingface.co/settings/tokens",
    "cost_per_1k_tokens": null,
    "free_tier_available": true,
    "free_tier_limits": "20 requests/minute",
    "recommended_use_cases": [
      "Advanced conversational AI",
      "Complex reasoning tasks",
      "Multi-turn dialogues",
      "Technical Q&A"
    ],
    "limitations": [
      "Requires HuggingFace account approval",
      "Larger model size requires more GPU memory",
      "Slower inference than 7B model"
    ],
    "documentation_url": "https://huggingface.co/meta-llama/Llama-2-13b-chat-hf",
    "model_card_url": "https://huggingface.co/meta-llama/Llama-2-13b-chat-hf",
    "supported_languages": [
      "en",
      "es",
      "fr",
      "de",
      "it",
      "pt",
      "pl",
      "ru",
      "ja",
      "ko",
      "zh"
    ],
    "max_output_tokens": 4096,
    "default_temperature": 0.7,
    "default_max_tokens": 512
  },
  "meta-llama/Meta-Llama-3-8B-Instruct": {
    "model_id": "meta-llama/Meta-Llama-3-8B-Instruct",
    "name": "Llama 3 8B Instruct",
    "provider": "huggingface",
    "type": "instruct",
    "access_method": "both",
    "description": "Meta's latest Llama 3 8B instruction-tuned model with improved performance",
    "api_endpoint": {
      "url": "https://api-inference.huggingface.co/models/meta-llama/Meta-Llama-3-8B-Instruct",
      "method": "POST",
      "auth_required": true,
      "rate_limit": "30 requests/minute (free tier)"
    },
    "local_endpoint": "meta-llama/Meta-Llama-3-8B-Instruct",
    "specs": {
      "parameters": 8,
      "context_window": 8192,
      "architecture": "Transformer"
    },
    "license": "Llama 3 Community License",
    "license_url": "https://llama.meta.com/llama3/license/",
    "api_key_required": true,
    "api_key_env_var": "HUGGINGFACE_API_KEY",
    "api_key_url": "https://huggingface.co/settings/tokens",
    "cost_per_1k_tokens": null,
    "free_tier_available": true,
    "free_tier_limits": "30 requests/minute",
    "recommended_use_cases": [
      "Instruction following",
      "Code generation",
      "Reasoning tasks",
      "Multi-step problem solving"
    ],
    "limitations": [
      "Requires HuggingFace account approval",
      "Newer model, may have less community support"
    ],
    "documentation_url": "https://huggingface.co/meta-llama/Meta-Llama-3-8B-Instruct",
    "model_card_url": "https://huggingface.co/meta-llama/Meta-Llama-3-8B-Instruct",
    "supported_languages": [
      "en",
      "es",
      "fr",
      "de",
      "it",
      "pt",
      "pl",
      "ru",
      "ja",
      "ko",
      "zh"
    ],
    "max_output_tokens": 8192,
    "default_temperature": 0.7,
    "default_max_tokens": 512
  },
  "mistralai/Mistral-7B-Instruct-v0.2": {
    "model_id": "mistralai/Mistral-7B-Instruct-v0.2",
    "name": "Mistral 7B Instruct v0.2",
    "provider": "huggingface",
    "type": "instruct",
    "access_method": "both",
    "description": "Mistral AI's 7B instruction-tuned model optimized for following instructions",
    "api_endpoint": {
      "url": "https://api-inference.huggingface.co/models/mistralai/Mistral-7B-Instruct-v0.2",
      "method": "POST",
      "auth_required": true,
      "rate_limit": "30 requests/minute (free tier)"
    },
    "local_endpoint": "mistralai/Mistral-7B-Instruct-v0.2",
    "specs": {
      "parameters": 7,
      "context_window": 8192,
      "architecture": "Transformer"
    },
    "license": "Apache-2.0",
    "license_url": "https://www.apache.org/licenses/LICENSE-2.0",
    "api_key_required": true,
    "api_key_env_var": "HUGGINGFACE_API_KEY",
    "api_key_url": "https://huggingface.co/settings/tokens",
    "cost_per_1k_tokens": null,
    "free_tier_available": true,
    "free_tier_limits": "30 requests/minute",
    "recommended_use_cases": [
      "Instruction following",
      "Code generation",
      "Text summarization",
      "Question answering"
    ],
    "limitations": [
      "May require GPU for optimal performance",
      "Context window limited to 8K tokens"
    ],
    "documentation_url": "https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.2",
    "model_card_url": "https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.2",
    "supported_languages": [
      "en",
      "es",
      "fr",
      "de",
      "it"
    ],
    "max_output_tokens": 8192,
    "default_temperature": 0.7,
    "default_max_tokens": 512
  },
  "microsoft/DialoGPT-large": {
    "model_id": "microsoft/DialoGPT-large",
    "name": "DialoGPT Large",
    "provider": "huggingface",
    "type": "chat",
    "access_method": "both",
    "description": "Microsoft's conversational AI model trained on Reddit dialogues",
    "api_endpoint": {
      "url": "https://api-inference.huggingface.co/models/microsoft/DialoGPT-large",
      "method": "POST",
      "auth_required": true,
      "rate_limit": "30 requests/minute (free tier)"
    },
    "local_endpoint": "microsoft/DialoGPT-large",
    "specs": {
      "parameters": 0.774,
      "context_window": 1024,
      "architecture": "GPT-2 based"
    },
    "license": "MIT",
    "license_url": "https://opensource.org/licenses/MIT",
    "api_key_required": true,
    "api_key_env_var": "HUGGINGFACE_API_KEY",
    "api_key_url": "https://huggingface.co/settings/tokens",
    "cost_per_1k_tokens": null,
    "free_tier_available": true,
    "free_tier_limits": "30 requests/minute",
    "recommended_use_cases": [
      "Casual conversation",
      "Chatbot applications",
      "Dialogue generation"
    ],
    "limitations": [
      "Smaller context window (1K tokens)",
      "May generate repetitive responses",
      "Trained on Reddit data, may have biases"
    ],
    "documentation_url": "https://huggingface.co/microsoft/DialoGPT-large",
    "model_card_url": "https://huggingface.co/microsoft/DialoGPT-large",
    "supported_languages": [
      "en"
    ],
    "max_output_tokens": 1024,
    "default_temperature": 0.7,
    "default_max_tokens": 512
  },
  "google/flan-t5-xxl": {
    "model_id": "google/flan-t5-xxl",
    "name": "FLAN-T5 XXL",
    "provider": "huggingface",
    "type": "instruct",
    "access_method": "both",
    "description": "Google's instruction-tuned T5 model with 11B parameters",
    "api_endpoint": {
      "url": "https://api-inference.huggingface.co/models/google/flan-t5-xxl",
      "method": "POST",
      "auth_required": true,
      "rate_limit": "20 requests/minute (free tier)"
    },
    "local_endpoint": "google/flan-t5-xxl",
    "specs": {
      "parameters": 11,
      "context_window": 512,
      "architecture": "T5 (Encoder-Decoder)"
    },
    "license": "Apache-2.0",
    "license_url": "https://www.apache.org/licenses/LICENSE-2.0",
    "api_key_required": true,
    "api_key_env_var": "HUGGINGFACE_API_KEY",
    "api_key_url": "https://huggingface.co/settings/tokens",
    "cost_per_1k_tokens": null,
    "free_tier_available": true,
    "free_tier_limits": "20 requests/minute",
    "recommended_use_cases": [
      "Instruction following",
      "Text summarization",
      "Question answering",
      "Translation"
    ],
    "limitations": [
      "Smaller context window (512 tokens)",
      "Encoder-decoder architecture may be slower",
      "Requires significant GPU memory"
    ],
    "documentation_url": "https://huggingface.co/google/flan-t5-xxl",
    "model_card_url": "https://huggingface.co/google/flan-t5-xxl",
    "supported_languages": [
      "en",
      "es",
      "fr",
      "de",
      "it",
      "pt",
      "ru",
      "zh",
      "ja"
    ],
    "max_output_tokens": 512,
    "default_temperature": 0.7,
    "default_max_tokens": 256
  },
  "HuggingFaceH4/zephyr-7b-beta": {
    "model_id": "HuggingFaceH4/zephyr-7b-beta",
    "name": "Zephyr 7B Beta",
    "provider": "huggingface",
    "type": "instruct",
    "access_method": "both",
    "description": "HuggingFace's Zephyr instruction-tuned model based on Mistral 7B",
    "api_endpoint": {
      "url": "https://api-inference.huggingface.co/models/HuggingFaceH4/zephyr-7b-beta",
      "method": "POST",
      "auth_required": true,
      "rate_limit": "30 requests/minute (free tier)"
    },
    "local_endpoint": "HuggingFaceH4/zephyr-7b-beta",
    "specs": {
      "parameters": 7,
      "context_window": 8192,
      "architecture": "Transformer"
    },
    "license": "MIT",
    "license_url": "https://opensource.org/licenses/MIT",
    "api_key_required": true,
    "api_key_env_var": "HUGGINGFACE_API_KEY",
    "api_key_url": "https://huggingface.co/settings/tokens",
    "cost_per_1k_tokens": null,
    "free_tier_available": true,
    "free_tier_limits": "30 requests/minute",
    "recommended_use_cases": [
      "Instruction following",
      "Helpful assistant tasks",
      "Conversational AI",
      "General purpose tasks"
    ],
    "limitations": [
      "Beta version, may have stability issues",
      "May require GPU for optimal performance"
    ],
    "documentation_url": "https://huggingface.co/HuggingFaceH4/zephyr-7b-beta",
    "model_card_url": "https://huggingface.co/HuggingFaceH4/zephyr-7b-beta",
    "supported_languages": [
      "en"
    ],
    "max_output_tokens": 8192,
    "default_temperature": 0.7,
    "default_max_tokens": 512
  },
  "mistralai/Mixtral-8x7B-Instruct-v0.1": {
    "model_id": "mistralai/Mixtral-8x7B-Instruct-v0.1",
    "name": "Mixtral 8x7B Instruct",
    "provider": "huggingface",
    "type": "instruct",
    "access_method": "both",
    "description": "Mistral AI's mixture of experts model with 8x7B parameters",
    "api_endpoint": {
      "url": "https://api-inference.huggingface.co/models/mistralai/Mixtral-8x7B-Instruct-v0.1",
      "method": "POST",
      "auth_required": true,
      "rate_limit": "10 requests/minute (free tier)"
    },
    "local_endpoint": "mistralai/Mixtral-8x7B-Instruct-v0.1",
    "specs": {
      "parameters": 47,
      "context_window": 32768,
      "architecture": "Mixture of Experts (MoE)"
    },
    "license": "Apache-2.0",
    "license_url": "https://www.apache.org/licenses/LICENSE-2.0",
    "api_key_required": true,
    "api_key_env_var": "HUGGINGFACE_API_KEY",
    "api_key_url": "https://huggingface.co/settings/tokens",
    "cost_per_1k_tokens": null,
    "free_tier_available": true,
    "free_tier_limits": "10 requests/minute",
    "recommended_use_cases": [
      "Complex reasoning",
      "Code generation",
      "Long context tasks",
      "Multi-step problem solving"
    ],
    "limitations": [
      "Requires significant GPU memory",
      "Slower inference than single-expert models",
      "Higher API rate limits"
    ],
    "documentation_url": "https://huggingface.co/mistralai/Mixtral-8x7B-Instruct-v0.1",
    "model_card_url": "https://huggingface.co/mistralai/Mixtral-8x7B-Instruct-v0.1",
    "supported_languages": [
      "en",
      "es",
      "fr",
      "de",
      "it"
    ],
    "max_output_tokens": 32768,
    "default_temperature": 0.7,
    "default_max_tokens": 512
  },
  "Qwen/Qwen2.5-7B-Instruct": {
    "model_id": "Qwen/Qwen2.5-7B-Instruct",
    "name": "Qwen 2.5 7B Instruct",
    "provider": "huggingface",
    "type": "instruct",
    "access_method": "both",
    "description": "Alibaba's Qwen 2.5 7B instruction-tuned model with strong multilingual support",
    "api_endpoint": {
      "url": "https://api-inference.huggingface.co/models/Qwen/Qwen2.5-7B-Instruct",
      "method": "POST",
      "auth_required": true,
      "rate_limit": "30 requests/minute (free tier)"
    },
    "local_endpoint": "Qwen/Qwen2.5-7B-Instruct",
    "specs": {
      "parameters": 7,
      "context_window": 32768,
      "architecture": "Transformer"
    },
    "license": "Apache-2.0",
    "license_url": "https://www.apache.org/licenses/LICENSE-2.0",
    "api_key_required": true,
    "api_key_env_var": "HUGGINGFACE_API_KEY",
    "api_key_url": "https://huggingface.co/settings/tokens",
    "cost_per_1k_tokens": null,
    "free_tier_available": true,
    "free_tier_limits": "30 requests/minute",
    "recommended_use_cases": [
      "Multilingual tasks",
      "Code generation",
      "Reasoning tasks",
      "Long context processing"
    ],
    "limitations": [
      "May require GPU for optimal performance",
      "Newer model, less community support"
    ],
    "documentation_url": "https://huggingface.co/Qwen/Qwen2.5-7B-Instruct",
    "model_card_url": "https://huggingface.co/Qwen/Qwen2.5-7B-Instruct",
    "supported_languages": [
      "en",
      "zh",
      "es",
      "fr",
      "de",
      "it",
      "pt",
      "ru",
      "ja",
      "ko",
      "ar",
      "hi"
    ],
    "max_output_tokens": 32768,
    "default_temperature": 0.7,
    "default_max_tokens": 512
  },
  "google/gemma-7b-it": {
    "model_id": "google/gemma-7b-it",
    "name": "Gemma 7B Instruct",
    "provider": "huggingface",
    "type": "instruct",
    "access_method": "both",
    "description": "Google's Gemma 7B instruction-tuned model based on Gemini technology",
    "api_endpoint": {
      "url": "https://api-inference.huggingface.co/models/google/gemma-7b-it",
      "method": "POST",
      "auth_required": true,
      "rate_limit": "30 requests/minute (free tier)"
    },
    "local_endpoint": "google/gemma-7b-it",
    "specs": {
      "parameters": 7,
      "context_window": 8192,
      "architecture": "Transformer"
    },
    "license": "Custom",
    "license_url": "https://ai.google.dev/gemma/terms",
    "api_key_required": true,
    "api_key_env_var": "HUGGINGFACE_API_KEY",
    "api_key_url": "https://huggingface.co/settings/tokens",
    "cost_per_1k_tokens": null,
    "free_tier_available": true,
    "free_tier_limits": "30 requests/minute",
    "recommended_use_cases": [
      "Instruction following",
      "Text generation",
      "Question answering",
      "Code generation"
    ],
    "limitations": [
      "Custom license terms apply",
      "May require GPU for optimal performance"
    ],
    "documentation_url": "https://huggingface.co/google/gemma-7b-it",
    "model_card_url": "https://huggingface.co/google/gemma-7b-it",
    "supported_languages": [
      "en",
      "es",
      "fr",
      "de",
      "it",
      "pt",
      "ru",
      "ja",
      "ko",
      "zh"
    ],
    "max_output_tokens": 8192,
    "default_temperature": 0.7,
    "default_max_tokens": 512
  },
  "gpt-4": {
    "model_id": "gpt-4",
    "name": "GPT-4",
    "provider": "openai",
    "type": "chat",
    "access_method": "api",
    "description": "OpenAI's most capable model with advanced reasoning capabilities",
    "api_endpoint": {
      "url": "https://api.openai.com/v1/chat/completions",
      "method": "POST",
      "auth_required": true,
      "rate_limit": "Varies by tier (500-10,000 requests/minute)"
    },
    "local_endpoint": null,
    "specs": {
      "parameters": null,
      "context_window": 8192,
      "architecture": "Transformer (proprietary)"
    },
    "license": "Proprietary",
    "license_url": "https://openai.com/policies/terms-of-use",
    "api_key_required": true,
    "api_key_env_var": "OPENAI_API_KEY",
    "api_key_url": "https://platform.openai.com/api-keys",
    "cost_per_1k_tokens": 0.03,
    "free_tier_available": false,
    "free_tier_limits": null,
    "recommended_use_cases": [
      "Complex reasoning",
      "Code generation",
      "Creative writing",
      "Analysis and synthesis",
      "Advanced Q&A"
    ],
    "limitations": [
      "Proprietary model, no local access",
      "Requires paid API access",
      "Rate limits apply",
      "Context window limited to 8K tokens"
    ],
    "documentation_url": "https://platform.openai.com/docs/models/gpt-4",
    "model_card_url": null,
    "supported_languages": [
      "en",
      "es",
      "fr",
      "de",
      "it",
      "pt",
      "ru",
      "ja",
      "ko",
      "zh",
      "ar",
      "hi"
    ],
    "max_output_tokens": 8192,
    "default_temperature": 0.7,
    "default_max_tokens": 512
  },
  "gpt-4-turbo": {
    "model_id": "gpt-4-turbo",
    "name": "GPT-4 Turbo",
    "provider": "openai",
    "type": "chat",
    "access_method": "api",
    "description": "Faster and more capable GPT-4 variant with extended context window",
    "api_endpoint": {
      "url": "https://api.openai.com/v1/chat/completions",
      "method": "POST",
      "auth_required": true,
      "rate_limit": "Varies by tier (500-10,000 requests/minute)"
    },
    "local_endpoint": null,
    "specs": {
      "parameters": null,
      "context_window": 128000,
      "architecture": "Transformer (proprietary)"
    },
    "license": "Proprietary",
    "license_url": "https://openai.com/policies/terms-of-use",
    "api_key_required": true,
    "api_key_env_var": "OPENAI_API_KEY",
    "api_key_url": "https://platform.openai.com/api-keys",
    "cost_per_1k_tokens": 0.01,
    "free_tier_available": false,
    "free_tier_limits": null,
    "recommended_use_cases": [
      "Long context processing",
      "Document analysis",
      "Code generation",
      "Complex reasoning",
      "Multimodal tasks"
    ],
    "limitations": [
      "Proprietary model",
      "Requires paid API access",
      "Higher cost than GPT-3.5"
    ],
    "documentation_url": "https://platform.openai.com/docs/models/gpt-4-turbo",
    "model_card_url": null,
    "supported_languages": [
      "en",
      "es",
      "fr",
      "de",
      "it",
      "pt",
      "ru",
      "ja",
      "ko",
      "zh",
      "ar",
      "hi"
    ],
    "max_output_tokens": 16384,
    "default_temperature": 0.7,
    "default_max_tokens": 4096
  },
  "gpt-4-turbo-preview": {
    "model_id": "gpt-4-turbo-preview",
    "name": "GPT-4 Turbo Preview",
    "provider": "openai",
    "type": "chat",
    "access_method": "api",
    "description": "Preview version of GPT-4 Turbo with latest improvements",
    "api_endpoint": {
      "url": "https://api.openai.com/v1/chat/completions",
      "method": "POST",
      "auth_required": true,
      "rate_limit": "Varies by tier"
    },
    "local_endpoint": null,
    "specs": {
      "parameters": null,
      "context_window": 128000,
      "architecture": "Transformer (proprietary)"
    },
    "license": "Proprietary",
    "license_url": "https://openai.com/policies/terms-of-use",
    "api_key_required": true,
    "api_key_env_var": "OPENAI_API_KEY",
    "api_key_url": "https://platform.openai.com/api-keys",
    "cost_per_1k_tokens": 0.01,
    "free_tier_available": false,
    "free_tier_limits": null,
    "recommended_use_cases": [
      "Testing new features",
      "Long context tasks",
      "Advanced reasoning"
    ],
    "limitations": [
      "Preview version, may change",
      "Proprietary model",
      "Requires paid access"
    ],
    "documentation_url": "https://platform.openai.com/docs/models/gpt-4-turbo",
    "model_card_url": null,
    "supported_languages": [
      "en",
      "es",
      "fr",
      "de",
      "it",
      "pt",
      "ru",
      "ja",
      "ko",
      "zh"
    ],
    "max_output_tokens": 16384,
    "default_temperature": 0.7,
    "default_max_tokens": 4096
  },
  "gpt-3.5-turbo": {
    "model_id": "gpt-3.5-turbo",
    "name": "GPT-3.5 Turbo",
    "provider": "openai",
    "type": "chat",
    "access_method": "api",
    "description": "Fast and efficient GPT-3.5 model optimized for speed and cost",
    "api_endpoint": {
      "url": "https://api.openai.com/v1/chat/completions",
      "method": "POST",
      "auth_required": true,
      "rate_limit": "Varies by tier (3,500-10,000 requests/minute)"
    },
    "local_endpoint": null,
    "specs": {
      "parameters": null,
      "context_window": 16385,
      "architecture": "Transformer (proprietary)"
    },
    "license": "Proprietary",
    "license_url": "https://openai.com/policies/terms-of-use",
    "api_key_required": true,
    "api_key_env_var": "OPENAI_API_KEY",
    "api_key_url": "https://platform.openai.com/api-keys",
    "cost_per_1k_tokens": 0.0005,
    "free_tier_available": false,
    "free_tier_limits": null,
    "recommended_use_cases": [
      "General purpose chat",
      "Quick responses",
      "Cost-effective applications",
      "High-volume tasks"
    ],
    "limitations": [
      "Proprietary model",
      "Requires paid API access",
      "Less capable than GPT-4"
    ],
    "documentation_url": "https://platform.openai.com/docs/models/gpt-3-5-turbo",
    "model_card_url": null,
    "supported_languages": [
      "en",
      "es",
      "fr",
      "de",
      "it",
      "pt",
      "ru",
      "ja",
      "ko",
      "zh"
    ],
    "max_output_tokens": 16385,
    "default_temperature": 0.7,
    "default_max_tokens": 4096
  },
  "gpt-3.5-turbo-16k": {
    "model_id": "gpt-3.5-turbo-16k",
    "name": "GPT-3.5 Turbo 16K",
    "provider": "openai",
    "type": "chat",
    "access_method": "api",
    "description": "GPT-3.5 Turbo with extended 16K context window",
    "api_endpoint": {
      "url": "https://api.openai.com/v1/chat/completions",
      "method": "POST",
      "auth_required": true,
      "rate_limit": "Varies by tier"
    },
    "local_endpoint": null,
    "specs": {
      "parameters": null,
      "context_window": 16385,
      "architecture": "Transformer (proprietary)"
    },
    "license": "Proprietary",
    "license_url": "https://openai.com/policies/terms-of-use",
    "api_key_required": true,
    "api_key_env_var": "OPENAI_API_KEY",
    "api_key_url": "https://platform.openai.com/api-keys",
    "cost_per_1k_tokens": 0.003,
    "free_tier_available": false,
    "free_tier_limits": null,
    "recommended_use_cases": [
      "Long documents",
      "Extended conversations",
      "Context-heavy tasks"
    ],
    "limitations": [
      "Proprietary model",
      "Requires paid access",
      "Higher cost than standard GPT-3.5"
    ],
    "documentation_url": "https://platform.openai.com/docs/models/gpt-3-5-turbo",
    "model_card_url": null,
    "supported_languages": [
      "en",
      "es",
      "fr",
      "de",
      "it",
      "pt",
      "ru",
      "ja",
      "ko",
      "zh"
    ],
    "max_output_tokens": 16385,
    "default_temperature": 0.7,
    "default_max_tokens": 4096
  },
  "gpt-4o": {
    "model_id": "gpt-4o",
    "name": "GPT-4o",
    "provider": "openai",
    "type": "multimodal",
    "access_method": "api",
    "description": "OpenAI's latest multimodal model optimized for speed and cost",
    "api_endpoint": {
      "url": "https://api.openai.com/v1/chat/completions",
      "method": "POST",
      "auth_required": true,
      "rate_limit": "Varies by tier"
    },
    "local_endpoint": null,
    "specs": {
      "parameters": null,
      "context_window": 128000,
      "architecture": "Transformer (proprietary)"
    },
    "license": "Proprietary",
    "license_url": "https://openai.com/policies/terms-of-use",
    "api_key_required": true,
    "api_key_env_var": "OPENAI_API_KEY",
    "api_key_url": "https://platform.openai.com/api-keys",
    "cost_per_1k_tokens": 0.005,
    "free_tier_available": false,
    "free_tier_limits": null,
    "recommended_use_cases": [
      "Multimodal tasks",
      "Vision and text",
      "Fast responses",
      "Cost-effective advanced tasks"
    ],
    "limitations": [
      "Proprietary model",
      "Requires paid access",
      "Newer model, may have less documentation"
    ],
    "documentation_url": "https://platform.openai.com/docs/models/gpt-4o",
    "model_card_url": null,
    "supported_languages": [
      "en",
      "es",
      "fr",
      "de",
      "it",
      "pt",
      "ru",
      "ja",
      "ko",
      "zh",
      "ar",
      "hi"
    ],
    "max_output_tokens": 16384,
    "default_temperature": 0.7,
    "default_max_tokens": 4096
  },
  "gpt-4o-mini": {
    "model_id": "gpt-4o-mini",
    "name": "GPT-4o Mini",
    "provider": "openai",
    "type": "multimodal",
    "access_method": "api",
    "description": "Smaller, faster, and more affordable version of GPT-4o",
    "api_endpoint": {
      "url": "https://api.openai.com/v1/chat/completions",
      "method": "POST",
      "auth_required": true,
      "rate_limit": "Varies by tier"
    },
    "local_endpoint": null,
    "specs": {
      "parameters": null,
      "context_window": 128000,
      "architecture": "Transformer (proprietary)"
    },
    "license": "Proprietary",
    "license_url": "https://openai.com/policies/terms-of-use",
    "api_key_required": true,
    "api_key_env_var": "OPENAI_API_KEY",
    "api_key_url": "https://platform.openai.com/api-keys",
    "cost_per_1k_tokens": 0.00015,
    "free_tier_available": false,
    "free_tier_limits": null,
    "recommended_use_cases": [
      "Cost-effective multimodal tasks",
      "High-volume applications",
      "Quick responses",
      "General purpose chat"
    ],
    "limitations": [
      "Proprietary model",
      "Requires paid access",
      "Less capable than GPT-4o"
    ],
    "documentation_url": "https://platform.openai.com/docs/models/gpt-4o-mini",
    "model_card_url": null,
    "supported_languages": [
      "en",
      "es",
      "fr",
      "de",
      "it",
      "pt",
      "ru",
      "ja",
      "ko",
      "zh"
    ],
    "max_output_tokens": 16384,
    "default_temperature": 0.7,
    "default_max_tokens": 4096
  }
}
